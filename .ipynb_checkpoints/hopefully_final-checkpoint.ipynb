{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba99390",
   "metadata": {},
   "source": [
    "# COMP-4730 Final Project\n",
    "**Created by Saffa Alvi, Nour ElKott, & Nandini Patel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7516da",
   "metadata": {},
   "source": [
    "## Objective\n",
    "> The purpose of this research data analysis project is to apply deep learning approaches to explore Natural Language Processing (NLP), and to create a model for the Google QUEST Q&A Labeling competition on Kaggle.com. \n",
    "\n",
    "> The objective of this competition is to use a new dataset, compiled by the CrowdSource team at Google, to create a predictive model “for different subjective aspects of question-answering” [1]. The goal of this project is to build a performative model to accurately predict the classes of the unlabeled data and to answer the research questions, defined in this report, that are related to NLP and this competition topic. Our model accuracy will also be compared to other existing models and evaluated to see which properties/characteristics of our model affect its overall accuracy. \n",
    "\n",
    "> The accomplishment of this research project benefits from the help and direction from our professor - Dr. Robin Gras and a few online resources, which were of great help.\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72188190",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "The following libraries, functions, etc were imported to help with constructing the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86ea727e-9c3c-4192-a157-bc462996fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68570122-94f0-4798-bd54-6a5707c5b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Concatenate, TimeDistributed, Bidirectional,GRU, Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D,SimpleRNN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366354f9",
   "metadata": {},
   "source": [
    "## Training Set, Testing Set, and Submission File\n",
    "\n",
    "The data provided to complete this project are the following:\n",
    "<br />**train.csv**\n",
    "<br />contains training set of questions and answers\n",
    "<br /> **test.csv**\n",
    "<br /> contains testing set of questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c00d40",
   "metadata": {},
   "source": [
    "Here, the program reads the three .csv files and saves the contents into the corresponding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f1f442da-9302-48cd-a803-0fb6ecb9cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet      = pd.read_csv('train.csv')\n",
    "testingSet       = pd.read_csv('test.csv')\n",
    "sampleSubmission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3327325",
   "metadata": {},
   "source": [
    "**Display the Target Variables in the Training Data Set**\n",
    "<br/> The targets all have a value between 0 and 1, inclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44e41a16-8b00-4fd7-a50c-2cff879b6b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.698525</td>\n",
       "      <td>0.772633</td>\n",
       "      <td>0.793689</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>0.507275</td>\n",
       "      <td>0.238745</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.429978</td>\n",
       "      <td>0.284915</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.497587</td>\n",
       "      <td>0.166063</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.654823</td>\n",
       "      <td>0.960054</td>\n",
       "      <td>0.968626</td>\n",
       "      <td>0.854680</td>\n",
       "      <td>0.479547</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.908254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.132047</td>\n",
       "      <td>0.219470</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>0.303023</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.185987</td>\n",
       "      <td>0.335057</td>\n",
       "      <td>0.045782</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.368826</td>\n",
       "      <td>0.153635</td>\n",
       "      <td>0.074240</td>\n",
       "      <td>0.138065</td>\n",
       "      <td>0.197582</td>\n",
       "      <td>0.423138</td>\n",
       "      <td>0.257301</td>\n",
       "      <td>0.383384</td>\n",
       "      <td>0.020489</td>\n",
       "      <td>0.178420</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>0.086926</td>\n",
       "      <td>0.074631</td>\n",
       "      <td>0.130743</td>\n",
       "      <td>0.422921</td>\n",
       "      <td>0.225718</td>\n",
       "      <td>0.407097</td>\n",
       "      <td>0.100708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_asker_intent_understanding  question_body_critical  \\\n",
       "count                          6079.000000             6079.000000   \n",
       "mean                              0.892663                0.595301   \n",
       "std                               0.132047                0.219470   \n",
       "min                               0.333333                0.333333   \n",
       "25%                               0.777778                0.444444   \n",
       "50%                               0.888889                0.555556   \n",
       "75%                               1.000000                0.777778   \n",
       "max                               1.000000                1.000000   \n",
       "\n",
       "       question_conversational  question_expect_short_answer  \\\n",
       "count              6079.000000                   6079.000000   \n",
       "mean                  0.057301                      0.698525   \n",
       "std                   0.182196                      0.350938   \n",
       "min                   0.000000                      0.000000   \n",
       "25%                   0.000000                      0.500000   \n",
       "50%                   0.000000                      0.666667   \n",
       "75%                   0.000000                      1.000000   \n",
       "max                   1.000000                      1.000000   \n",
       "\n",
       "       question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "count            6079.000000                            6079.000000   \n",
       "mean                0.772633                               0.793689   \n",
       "std                 0.303023                               0.336622   \n",
       "min                 0.000000                               0.000000   \n",
       "25%                 0.666667                               0.666667   \n",
       "50%                 1.000000                               1.000000   \n",
       "75%                 1.000000                               1.000000   \n",
       "max                 1.000000                               1.000000   \n",
       "\n",
       "       question_interestingness_others  question_interestingness_self  \\\n",
       "count                      6079.000000                    6079.000000   \n",
       "mean                          0.587478                       0.507275   \n",
       "std                           0.135900                       0.185987   \n",
       "min                           0.333333                       0.333333   \n",
       "25%                           0.444444                       0.333333   \n",
       "50%                           0.555556                       0.444444   \n",
       "75%                           0.666667                       0.666667   \n",
       "max                           1.000000                       1.000000   \n",
       "\n",
       "       question_multi_intent  question_not_really_a_question  \\\n",
       "count            6079.000000                     6079.000000   \n",
       "mean                0.238745                        0.004469   \n",
       "std                 0.335057                        0.045782   \n",
       "min                 0.000000                        0.000000   \n",
       "25%                 0.000000                        0.000000   \n",
       "50%                 0.000000                        0.000000   \n",
       "75%                 0.333333                        0.000000   \n",
       "max                 1.000000                        1.000000   \n",
       "\n",
       "       question_opinion_seeking  question_type_choice  question_type_compare  \\\n",
       "count               6079.000000           6079.000000            6079.000000   \n",
       "mean                   0.429978              0.284915               0.038137   \n",
       "std                    0.365952              0.368826               0.153635   \n",
       "min                    0.000000              0.000000               0.000000   \n",
       "25%                    0.000000              0.000000               0.000000   \n",
       "50%                    0.333333              0.000000               0.000000   \n",
       "75%                    0.666667              0.666667               0.000000   \n",
       "max                    1.000000              1.000000               1.000000   \n",
       "\n",
       "       question_type_consequence  question_type_definition  \\\n",
       "count                6079.000000               6079.000000   \n",
       "mean                    0.010035                  0.030762   \n",
       "std                     0.074240                  0.138065   \n",
       "min                     0.000000                  0.000000   \n",
       "25%                     0.000000                  0.000000   \n",
       "50%                     0.000000                  0.000000   \n",
       "75%                     0.000000                  0.000000   \n",
       "max                     1.000000                  1.000000   \n",
       "\n",
       "       question_type_entity  question_type_instructions  \\\n",
       "count           6079.000000                 6079.000000   \n",
       "mean               0.065225                    0.497587   \n",
       "std                0.197582                    0.423138   \n",
       "min                0.000000                    0.000000   \n",
       "25%                0.000000                    0.000000   \n",
       "50%                0.000000                    0.666667   \n",
       "75%                0.000000                    1.000000   \n",
       "max                1.000000                    1.000000   \n",
       "\n",
       "       question_type_procedure  question_type_reason_explanation  \\\n",
       "count              6079.000000                       6079.000000   \n",
       "mean                  0.166063                          0.386385   \n",
       "std                   0.257301                          0.383384   \n",
       "min                   0.000000                          0.000000   \n",
       "25%                   0.000000                          0.000000   \n",
       "50%                   0.000000                          0.333333   \n",
       "75%                   0.333333                          0.666667   \n",
       "max                   1.000000                          1.000000   \n",
       "\n",
       "       question_type_spelling  question_well_written  answer_helpful  \\\n",
       "count             6079.000000            6079.000000     6079.000000   \n",
       "mean                 0.000823               0.799931        0.925408   \n",
       "std                  0.020489               0.178420        0.114836   \n",
       "min                  0.000000               0.333333        0.333333   \n",
       "25%                  0.000000               0.666667        0.888889   \n",
       "50%                  0.000000               0.833333        1.000000   \n",
       "75%                  0.000000               1.000000        1.000000   \n",
       "max                  0.666667               1.000000        1.000000   \n",
       "\n",
       "       answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "count                  6079.000000       6079.000000       6079.000000   \n",
       "mean                      0.654823          0.960054          0.968626   \n",
       "std                       0.107666          0.086926          0.074631   \n",
       "min                       0.333333          0.333333          0.333333   \n",
       "25%                       0.666667          1.000000          1.000000   \n",
       "50%                       0.666667          1.000000          1.000000   \n",
       "75%                       0.666667          1.000000          1.000000   \n",
       "max                       1.000000          1.000000          1.000000   \n",
       "\n",
       "       answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "count          6079.000000               6079.000000            6079.000000   \n",
       "mean              0.854680                  0.479547               0.130641   \n",
       "std               0.130743                  0.422921               0.225718   \n",
       "min               0.200000                  0.000000               0.000000   \n",
       "25%               0.800000                  0.000000               0.000000   \n",
       "50%               0.866667                  0.500000               0.000000   \n",
       "75%               0.933333                  1.000000               0.333333   \n",
       "max               1.000000                  1.000000               1.000000   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                     6079.000000          6079.000000  \n",
       "mean                         0.502468             0.908254  \n",
       "std                          0.407097             0.100708  \n",
       "min                          0.000000             0.333333  \n",
       "25%                          0.000000             0.888889  \n",
       "50%                          0.500000             0.888889  \n",
       "75%                          1.000000             1.000000  \n",
       "max                          1.000000             1.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "targets = list(sampleSubmission.columns[1:])\n",
    "trainingSet[targets].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb894a8",
   "metadata": {},
   "source": [
    "**Display the Training Set Size**\n",
    "<br />**Training Set** is composed of:\n",
    "<br />41 columns for Q&A classifications (ex. question_title, answer_helpful, etc).\n",
    "<br />6079 rows for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "181f4ab9-f397-41ed-b959-0d26157bfb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size (rows, cols):  (6079, 41)\n",
      "\n",
      "LIST OF COLUMN NAMES IN TRAINING SET:\n",
      "----------------------------------------\n",
      "1 .  qa_id\n",
      "2 .  question_title\n",
      "3 .  question_body\n",
      "4 .  question_user_name\n",
      "5 .  question_user_page\n",
      "6 .  answer\n",
      "7 .  answer_user_name\n",
      "8 .  answer_user_page\n",
      "9 .  url\n",
      "10 .  category\n",
      "11 .  host\n",
      "12 .  question_asker_intent_understanding\n",
      "13 .  question_body_critical\n",
      "14 .  question_conversational\n",
      "15 .  question_expect_short_answer\n",
      "16 .  question_fact_seeking\n",
      "17 .  question_has_commonly_accepted_answer\n",
      "18 .  question_interestingness_others\n",
      "19 .  question_interestingness_self\n",
      "20 .  question_multi_intent\n",
      "21 .  question_not_really_a_question\n",
      "22 .  question_opinion_seeking\n",
      "23 .  question_type_choice\n",
      "24 .  question_type_compare\n",
      "25 .  question_type_consequence\n",
      "26 .  question_type_definition\n",
      "27 .  question_type_entity\n",
      "28 .  question_type_instructions\n",
      "29 .  question_type_procedure\n",
      "30 .  question_type_reason_explanation\n",
      "31 .  question_type_spelling\n",
      "32 .  question_well_written\n",
      "33 .  answer_helpful\n",
      "34 .  answer_level_of_information\n",
      "35 .  answer_plausible\n",
      "36 .  answer_relevance\n",
      "37 .  answer_satisfaction\n",
      "38 .  answer_type_instructions\n",
      "39 .  answer_type_procedure\n",
      "40 .  answer_type_reason_explanation\n",
      "41 .  answer_well_written\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size (rows, cols): \", trainingSet.shape)\n",
    "\n",
    "trainingSetCols = trainingSet.columns\n",
    "n = 1\n",
    "\n",
    "print(\"\\nLIST OF COLUMN NAMES IN TRAINING SET:\")\n",
    "print(\"----------------------------------------\")\n",
    "for i in trainingSetCols:\n",
    "    print(n, \". \", i)\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f519e35",
   "metadata": {},
   "source": [
    "**Display the Testing Set Size**\n",
    "<br />**Testing Set** is composed of:\n",
    "<br />11 columns for Q&A classifications (ex. question_title, answer_user_name, etc).\n",
    "<br />476 rows for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "920361a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Size (rows, cols):  (476, 11)\n",
      "\n",
      "LIST OF COLUMN NAMES IN TESTING SET:\n",
      "----------------------------------------\n",
      "1 .  qa_id\n",
      "2 .  question_title\n",
      "3 .  question_body\n",
      "4 .  question_user_name\n",
      "5 .  question_user_page\n",
      "6 .  answer\n",
      "7 .  answer_user_name\n",
      "8 .  answer_user_page\n",
      "9 .  url\n",
      "10 .  category\n",
      "11 .  host\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Set Size (rows, cols): \", testingSet.shape)\n",
    "\n",
    "testingSetCols = testingSet.columns\n",
    "n = 1\n",
    "\n",
    "print(\"\\nLIST OF COLUMN NAMES IN TESTING SET:\")\n",
    "print(\"----------------------------------------\")\n",
    "for i in testingSetCols:\n",
    "    print(n, \". \", i)\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44efbc",
   "metadata": {},
   "source": [
    "**Display the contents of the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d823e29d-0ae5-4ec6-b7bb-fd55de3b696f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>photo.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>rpg.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>electronics.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>judaism.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>graphicdesign.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question_title  \\\n",
       "0  What am I losing when using extension tubes in...   \n",
       "1  What is the distinction between a city and a s...   \n",
       "2  Maximum protusion length for through-hole comp...   \n",
       "3              Can an affidavit be used in Beit Din?   \n",
       "4       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS   \n",
       "\n",
       "                              host  \n",
       "0          photo.stackexchange.com  \n",
       "1            rpg.stackexchange.com  \n",
       "2    electronics.stackexchange.com  \n",
       "3        judaism.stackexchange.com  \n",
       "4  graphicdesign.stackexchange.com  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec936df0",
   "metadata": {},
   "source": [
    "## Building a Sentiment Classifier\n",
    "We will build a sentiment classifier and test its performance. The Sentiment Classifier will be generated by using the 'category' and 'question_body' columns of the training data. This will train the model to:\n",
    "1. Mine the data: ignore useless words, characters, etc in order to focus on the important content in the data\n",
    "2. Create a Recurrent Neural Network (RNN), to form an undirected graph of sequences of inputs. In this case, the inputs are the data in the **training set**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a628d7b9",
   "metadata": {},
   "source": [
    "## Begin Mining Data\n",
    "We will begin to remove any contents found in each question and answer in the dataset.\n",
    "The following will take place in order to keep useful information:\n",
    "1. remove URLS\n",
    "2. convert uppercase letters to lowercase letters\n",
    "3. remove tags\n",
    "4. remove words containing possible errors\n",
    "5. remove special characters\n",
    "6. remove 'stop words'\n",
    "7. stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fac5898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nour/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nour/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nour/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# will be used to remove the stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# will be used for stemming and lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc4e87",
   "metadata": {},
   "source": [
    "**Print a random Q&A in the training set before being processed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8eb44b87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM QUESTION BODY W/OUT MINING\n",
      "---------------------------------------------------------------\n",
      "I have a site that I am migrating to WordPress, and I have a need to add properties that each of the users can edit (e.g., Address, City, State, Business Name, etc), along with some properties that Administrators can edit (IsActive, CanEmail) that wouldn't be displayed to the user.  In addition, I need to be able to display the properties in a table (similar to how the plugin, \"Members List\", displays, but with the custom fields displaying as well.\n",
      "\n",
      "Given these requirements, I had attempted to use a combination of \"Cimy User Extra Fields\" and \"Members List\", but the members list grid did not have an option to display the extra fields created by the other plugin.\n",
      "\n",
      "How would you recommend I approach this?\n",
      "\n",
      "EDIT: \n",
      "\n",
      "So I guess the crux of my question is, what is the preferred method to add properties to the User?\n",
      "\n",
      "RANDOM ANSWER W/OUT MINING\n",
      "---------------------------------------------------------------\n",
      "To answer the first part of your question, I have just put my class TTT_User_Profile_Addon on GitHub. The class offers a simple interface to add a field to a profile page. I have added an example for a checkbox subclass and some code to initialize it per functions.php. This works in a plugin too, of course.\n",
      "\n",
      "There are some build in placeholders, but you can add your own. Separate filters for the markup and input values make extending the class easier.\n",
      "\n",
      "You can set custom capabilities for showing and saving the fields per constructor call. The whole work is reduced to a simple init function:\n",
      "\n",
      "add_action( 'init', 'ttt_init_profile_addons' );\n",
      "\n",
      "/**\n",
      " * Registers the extra fields for the user profile editor.\n",
      " */\n",
      "function ttt_init_profile_addons()\n",
      "{\n",
      "    $GLOBALS['ttt_show_profile'] = new TTT_User_Profile_Checkbox(\n",
      "        array (\n",
      "            'name' =&gt; 'ttt_show_profile'\n",
      "        ,   'label' =&gt; 'Show a short profile box on my posts.'\n",
      "        ,   'th' =&gt; ''\n",
      "        ,   'td' =&gt; '&lt;input type=\"checkbox\" name=\"%name%\" id=\"%id%\" %checked% /&gt; %label%'\n",
      "        ,   'cap_show' =&gt; 'edit_posts'\n",
      "        ,   'cap_save' =&gt; 'edit_users'\n",
      "        )\n",
      "    );\n",
      "    // add more fields here …\n",
      "}\n",
      "\n",
      "\n",
      "Adding the values to the member table is something I still have on my todo list …\n",
      "\n",
      "Oh, and I should probably mention another class to replace or extend the default contact fields: TTT_Contactfields. This may be a case of OOP overdone. :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM QUESTION BODY W/OUT MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['question_body'].values[344])\n",
    "\n",
    "print(\"RANDOM ANSWER W/OUT MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['answer'].values[344])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb63e03",
   "metadata": {},
   "source": [
    "**Mining Function**\n",
    "Remove any of the following texts that may be found in the questions and answers:\n",
    "<br />1. Web Links\n",
    "<br />2. Tags\n",
    "<br />3. Upper-case letters, convert to lower-case\n",
    "<br />4. Typos\n",
    "<br />5. Special characters\n",
    "<br />6. Lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b14f7cc-1767-473a-822b-19fd5b0b8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mineText(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\S*\\d\\S*\", \"\", text)\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in stopwords.words('english')])\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split(' ')])\n",
    "    return text\n",
    "\n",
    "trainingSet['question_body'] = trainingSet['question_body'].apply(mineText)\n",
    "trainingSet['answer'] = trainingSet['answer'].apply(mineText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e20e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM QUESTION BODY AFTER MINING\n",
      "---------------------------------------------------------------\n",
      "site migrating wordpress need add property user edit e g address city state business name etc along property administrator edit isactive canemail displayed user addition need able display property table similar plugin member list display custom field displaying well given requirement attempted use combination cimy user extra field member list member list grid option display extra field created plugin would recommend approach edit guess crux question preferred method add property user \n",
      "\n",
      "RANDOM ANSWER AFTER MINING\n",
      "---------------------------------------------------------------\n",
      "answer first part question put class ttt user profile addon github class offer simple interface add field profile page added example checkbox subclass code initialize per function php work plugin course build placeholder add separate filter markup input value make extending class easier set custom capability showing saving field per constructor call whole work reduced simple init function add action init ttt init profile addons register extra field user profile editor function ttt init profile addons globals ttt show profile new ttt user profile checkbox array name gt ttt show profile label gt show short profile box post th gt td gt lt input type checkbox name name id id checked gt label cap show gt edit post cap save gt edit user add field adding value member table something still todo list oh probably mention another class replace extend default contact field ttt contactfields may case oop overdone \n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM QUESTION BODY AFTER MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['question_body'].values[344])\n",
    "\n",
    "print(\"\\nRANDOM ANSWER AFTER MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['answer'].values[344])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad4196",
   "metadata": {},
   "source": [
    "## Creating a Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abbaa4",
   "metadata": {},
   "source": [
    "In this project, we will generate a simple model composed of the following layers:\n",
    "<br /> 1. Input: \n",
    "<br /> 2. Embedding: We will do this in order to have space for more semantic nuances in sentences.\n",
    "<br /> 3. Bidirectional RNN:\n",
    "<br /> 4. Global Max Pooling: \n",
    "<br /> 5. Dense Layer:\n",
    "<br /> 6. Dense Layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "776fc53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 768)         3840000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 120)         99480     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1936      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 3,941,501\n",
      "Trainable params: 3,941,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters used for typical embeddings\n",
    "maxLength = 1000\n",
    "maxFeatures = 5000 \n",
    "embeddingSize = 768\n",
    "\n",
    "inp = Input(shape=(maxLength,)) # returns a shape tuple of ints, size of the maxLength of \n",
    "\n",
    "z = Embedding(maxFeatures,embeddingSize,input_length = maxLength)(inp)\n",
    "z = Bidirectional(SimpleRNN(60,return_sequences='True'))(z)\n",
    "z = GlobalMaxPool1D()(z)\n",
    "z = Dense(16,activation='relu')(z)\n",
    "z = Dense(5,activation='softmax')(z)\n",
    "\n",
    "model = Model(inputs=inp,outputs=z)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c745327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADDED AND TOKENIZED SEQUENCES, ALL VECTORS HAVE THE SAME LENGTH\n",
      "----------------------------------------------------------------\n",
      "xTrain Sequence, Padded and Tokenized:  (4559, 1000)\n",
      "yTrain                               :  (4559,)\n",
      "xVal Sequence, Padded and Tokenized  :  (1520, 1000)\n",
      "yVal                                 :  (1520,)\n",
      "Epoch 1/10\n",
      "36/36 - 54s - loss: 1.3087 - accuracy: 0.4350 - val_loss: 1.0614 - val_accuracy: 0.5197\n",
      "Epoch 2/10\n",
      "36/36 - 62s - loss: 0.7407 - accuracy: 0.7951 - val_loss: 0.6744 - val_accuracy: 0.8263\n",
      "Epoch 3/10\n",
      "36/36 - 64s - loss: 0.3239 - accuracy: 0.9566 - val_loss: 0.4638 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "36/36 - 65s - loss: 0.1169 - accuracy: 0.9868 - val_loss: 0.4138 - val_accuracy: 0.8546\n",
      "Epoch 5/10\n",
      "36/36 - 64s - loss: 0.0519 - accuracy: 0.9945 - val_loss: 0.4162 - val_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "36/36 - 65s - loss: 0.0234 - accuracy: 0.9987 - val_loss: 0.4310 - val_accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "36/36 - 64s - loss: 0.0153 - accuracy: 0.9982 - val_loss: 0.4911 - val_accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "36/36 - 64s - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.4783 - val_accuracy: 0.8592\n",
      "Epoch 9/10\n",
      "36/36 - 64s - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.4868 - val_accuracy: 0.8625\n",
      "Epoch 10/10\n",
      "36/36 - 66s - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.4981 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2bc1b00040>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yLabel = LabelEncoder() # label encodeer\n",
    "labels = yLabel.fit_transform(trainingSet['category']) # used for the labels of each category\n",
    "\n",
    "yTrain = labels # set x training vars as the labels (categories)\n",
    "# setup the training (x,y) and testing (X,Y) 'question_body' datasets.  test_size default 0.25, random_state for shuffling data\n",
    "xTrain,xTest,yTrain, yTest = train_test_split(trainingSet['question_body'], yTrain, test_size=0.25,random_state=30)\n",
    "\n",
    "tokenizer = Tokenizer(num_words = maxFeatures) # setup the tokenizer, num words in question_body to vectorize\n",
    "tokenizer.fit_on_texts(list(xTrain)) # \n",
    "\n",
    "xVal = xTest # set xVal to xTest\n",
    "xVal = tokenizer.texts_to_sequences(xVal) # transform xVal into sequence of integers\n",
    "\n",
    "xTrain = tokenizer.texts_to_sequences(xTrain) # transform xTrain into sequence of integers\n",
    "\n",
    "xTrain = pad_sequences(xTrain, maxlen = maxLength) # pad sequence so that the vectors can have the same lengths\n",
    "xVal   = pad_sequences(xVal, maxlen = maxLength) # pad sequence so that the vectors can have the same lengths\n",
    "\n",
    "yVal = yTest\n",
    "\n",
    "print(\"PADDED AND TOKENIZED SEQUENCES, ALL VECTORS HAVE THE SAME LENGTH\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "print(\"xTrain Sequence, Padded and Tokenized: \", xTrain.shape)\n",
    "print(\"yTrain                               : \", yTrain.shape)\n",
    "\n",
    "print(\"xVal Sequence, Padded and Tokenized  : \", xVal.shape)\n",
    "print(\"yVal                                 : \", yVal.shape)\n",
    "\n",
    "\n",
    "model.fit(xTrain, yTrain, batch_size=128, epochs=10, verbose=2,validation_data = (xVal,yVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2869427d",
   "metadata": {},
   "source": [
    "**Embedding Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "30c03865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\")\n",
    "trainingSet['question_title'] = trainingSet['question_title'].apply(mineText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "697ae120",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionEmbedding = [model([trainingSet.iloc[i].question_title])[0] for i in range(trainingSet.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdfe580",
   "metadata": {},
   "source": [
    "**Testing the Sentiment Similarity Process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6de86326",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2594475462.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_40073/2594475462.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    return np.argmax(similarityVal)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def sentimentSimilarity(query):\n",
    "    queryEmbedding = model([query])\n",
    "    similarity = cosine_similarity(questionEmbedding, queryEmbedding)\n",
    "    similarityVal = [similarity[i][0] for i in range(similarity.shape[0])         \n",
    "    return np.argmax(similarityVal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2e95a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I am having an issue with accessing different OpenCV libraries. What are some functions that may help solve my issue?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db0ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE QUESTION\n",
      "-----------------------------\n",
      "I am having an issue with accessing different OpenCV libraries. What are some functions that may help solve my issue?\n",
      "\n",
      "PREPROCESSED QUESTION\n",
      "-----------------------------\n",
      "issue accessing different opencv library function may help solve issue \n",
      "(6079, 1)\n",
      "\n",
      "SEMANTIC SIMILARITY\n",
      "-----------------------------\n",
      "change default checkerboard blocksize opencv\n"
     ]
    }
   ],
   "source": [
    "print('SAMPLE QUESTION')\n",
    "print(\"-----------------------------\")\n",
    "print(question)\n",
    "\n",
    "print('\\nPREPROCESSED QUESTION')\n",
    "print(\"-----------------------------\")\n",
    "question = mineText(question)\n",
    "print(question)\n",
    "\n",
    "predictedQuery = sentimentSimilarity(question)\n",
    "\n",
    "print('\\nSEMANTIC SIMILARITY')\n",
    "print(\"-----------------------------\")\n",
    "print(trainingSet.iloc[predictedQuery].question_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba2751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ea727e-9c3c-4192-a157-bc462996fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68570122-94f0-4798-bd54-6a5707c5b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Concatenate, TimeDistributed, Bidirectional,GRU, Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D,SimpleRNN\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f442da-9302-48cd-a803-0fb6ecb9cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet      = pd.read_csv('train.csv')\n",
    "testingSet       = pd.read_csv('test.csv')\n",
    "sampleSubmission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e41a16-8b00-4fd7-a50c-2cff879b6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#trainingSet.head()\n",
    "#sampleSubmission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02301f39-6206-434b-8b9b-d947e66f18ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size (rows, cols):  (6079, 41)\n",
      "Testing  Set Size (rows, cols):  (476, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Size (rows, cols): \", trainingSet.shape)\n",
    "print(\"Testing  Set Size (rows, cols): \", testingSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181f4ab9-f397-41ed-b959-0d26157bfb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF COLUMN NAMES IN TRAINING SET:\n",
      "----------------------------------------\n",
      "1 .  qa_id\n",
      "2 .  question_title\n",
      "3 .  question_body\n",
      "4 .  question_user_name\n",
      "5 .  question_user_page\n",
      "6 .  answer\n",
      "7 .  answer_user_name\n",
      "8 .  answer_user_page\n",
      "9 .  url\n",
      "10 .  category\n",
      "11 .  host\n",
      "12 .  question_asker_intent_understanding\n",
      "13 .  question_body_critical\n",
      "14 .  question_conversational\n",
      "15 .  question_expect_short_answer\n",
      "16 .  question_fact_seeking\n",
      "17 .  question_has_commonly_accepted_answer\n",
      "18 .  question_interestingness_others\n",
      "19 .  question_interestingness_self\n",
      "20 .  question_multi_intent\n",
      "21 .  question_not_really_a_question\n",
      "22 .  question_opinion_seeking\n",
      "23 .  question_type_choice\n",
      "24 .  question_type_compare\n",
      "25 .  question_type_consequence\n",
      "26 .  question_type_definition\n",
      "27 .  question_type_entity\n",
      "28 .  question_type_instructions\n",
      "29 .  question_type_procedure\n",
      "30 .  question_type_reason_explanation\n",
      "31 .  question_type_spelling\n",
      "32 .  question_well_written\n",
      "33 .  answer_helpful\n",
      "34 .  answer_level_of_information\n",
      "35 .  answer_plausible\n",
      "36 .  answer_relevance\n",
      "37 .  answer_satisfaction\n",
      "38 .  answer_type_instructions\n",
      "39 .  answer_type_procedure\n",
      "40 .  answer_type_reason_explanation\n",
      "41 .  answer_well_written\n"
     ]
    }
   ],
   "source": [
    "tsCols = trainingSet.columns\n",
    "n = 1\n",
    "print(\"LIST OF COLUMN NAMES IN TRAINING SET:\")\n",
    "print(\"----------------------------------------\")\n",
    "for i in tsCols:\n",
    "    print(n, \". \", i)\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e033cb0-4a0a-4b7b-bea0-caae8145cc7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST OF COLUMN NAMES IN SUBMISSION FILE:\n",
      "----------------------------------------\n",
      "1 .  question_asker_intent_understanding\n",
      "2 .  question_body_critical\n",
      "3 .  question_conversational\n",
      "4 .  question_expect_short_answer\n",
      "5 .  question_fact_seeking\n",
      "6 .  question_has_commonly_accepted_answer\n",
      "7 .  question_interestingness_others\n",
      "8 .  question_interestingness_self\n",
      "9 .  question_multi_intent\n",
      "10 .  question_not_really_a_question\n",
      "11 .  question_opinion_seeking\n",
      "12 .  question_type_choice\n",
      "13 .  question_type_compare\n",
      "14 .  question_type_consequence\n",
      "15 .  question_type_definition\n",
      "16 .  question_type_entity\n",
      "17 .  question_type_instructions\n",
      "18 .  question_type_procedure\n",
      "19 .  question_type_reason_explanation\n",
      "20 .  question_type_spelling\n",
      "21 .  question_well_written\n",
      "22 .  answer_helpful\n",
      "23 .  answer_level_of_information\n",
      "24 .  answer_plausible\n",
      "25 .  answer_relevance\n",
      "26 .  answer_satisfaction\n",
      "27 .  answer_type_instructions\n",
      "28 .  answer_type_procedure\n",
      "29 .  answer_type_reason_explanation\n",
      "30 .  answer_well_written\n"
     ]
    }
   ],
   "source": [
    "target_cols = sampleSubmission.drop(['qa_id'], axis=1).columns.values\n",
    "n = 1\n",
    "print(\"LIST OF COLUMN NAMES IN SUBMISSION FILE:\")\n",
    "print(\"----------------------------------------\")\n",
    "for i in target_cols:\n",
    "    print(n, \". \", i)\n",
    "    n = n + 1\n",
    "\n",
    "xTrain = trainingSet.drop(np.concatenate([target_cols, np.array(['qa_id'])]), axis=1)\n",
    "yTrain = trainingSet[target_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d823e29d-0ae5-4ec6-b7bb-fd55de3b696f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>photo.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>rpg.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>electronics.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>judaism.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>graphicdesign.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question_title  \\\n",
       "0  What am I losing when using extension tubes in...   \n",
       "1  What is the distinction between a city and a s...   \n",
       "2  Maximum protusion length for through-hole comp...   \n",
       "3              Can an affidavit be used in Beit Din?   \n",
       "4       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS   \n",
       "\n",
       "                              host  \n",
       "0          photo.stackexchange.com  \n",
       "1            rpg.stackexchange.com  \n",
       "2    electronics.stackexchange.com  \n",
       "3        judaism.stackexchange.com  \n",
       "4  graphicdesign.stackexchange.com  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed929c6",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "(rewrite) We will build a sentiment classifier and test its performance. The Sentiment Classifier will be generated by using the 'category' and 'question_body' columns of the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa1442",
   "metadata": {},
   "source": [
    "# Begin Mining Data\n",
    "We will begin to remove any contents found in each question and answer in the dataset.\n",
    "The following will take place in order to keep useful information:\n",
    "1. remove URLS\n",
    "2. convert uppercase letters to lowercase letters\n",
    "3. remove tags\n",
    "4. remove words containing possible errors\n",
    "5. remove special characters\n",
    "6. remove 'stop words'\n",
    "7. stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac43cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nour/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nour/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/nour/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# will be used to remove the stop words\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# will be used for stemming and lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ac99b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM QUESTION BODY W/OUT MINING\n",
      "---------------------------------------------------------------\n",
      "I have a site that I am migrating to WordPress, and I have a need to add properties that each of the users can edit (e.g., Address, City, State, Business Name, etc), along with some properties that Administrators can edit (IsActive, CanEmail) that wouldn't be displayed to the user.  In addition, I need to be able to display the properties in a table (similar to how the plugin, \"Members List\", displays, but with the custom fields displaying as well.\n",
      "\n",
      "Given these requirements, I had attempted to use a combination of \"Cimy User Extra Fields\" and \"Members List\", but the members list grid did not have an option to display the extra fields created by the other plugin.\n",
      "\n",
      "How would you recommend I approach this?\n",
      "\n",
      "EDIT: \n",
      "\n",
      "So I guess the crux of my question is, what is the preferred method to add properties to the User?\n",
      "\n",
      "RANDOM ANSWER W/OUT MINING\n",
      "---------------------------------------------------------------\n",
      "To answer the first part of your question, I have just put my class TTT_User_Profile_Addon on GitHub. The class offers a simple interface to add a field to a profile page. I have added an example for a checkbox subclass and some code to initialize it per functions.php. This works in a plugin too, of course.\n",
      "\n",
      "There are some build in placeholders, but you can add your own. Separate filters for the markup and input values make extending the class easier.\n",
      "\n",
      "You can set custom capabilities for showing and saving the fields per constructor call. The whole work is reduced to a simple init function:\n",
      "\n",
      "add_action( 'init', 'ttt_init_profile_addons' );\n",
      "\n",
      "/**\n",
      " * Registers the extra fields for the user profile editor.\n",
      " */\n",
      "function ttt_init_profile_addons()\n",
      "{\n",
      "    $GLOBALS['ttt_show_profile'] = new TTT_User_Profile_Checkbox(\n",
      "        array (\n",
      "            'name' =&gt; 'ttt_show_profile'\n",
      "        ,   'label' =&gt; 'Show a short profile box on my posts.'\n",
      "        ,   'th' =&gt; ''\n",
      "        ,   'td' =&gt; '&lt;input type=\"checkbox\" name=\"%name%\" id=\"%id%\" %checked% /&gt; %label%'\n",
      "        ,   'cap_show' =&gt; 'edit_posts'\n",
      "        ,   'cap_save' =&gt; 'edit_users'\n",
      "        )\n",
      "    );\n",
      "    // add more fields here …\n",
      "}\n",
      "\n",
      "\n",
      "Adding the values to the member table is something I still have on my todo list …\n",
      "\n",
      "Oh, and I should probably mention another class to replace or extend the default contact fields: TTT_Contactfields. This may be a case of OOP overdone. :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM QUESTION BODY W/OUT MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['question_body'].values[344])\n",
    "\n",
    "print(\"RANDOM ANSWER W/OUT MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['answer'].values[344])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b14f7cc-1767-473a-822b-19fd5b0b8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(s):\n",
    "  return re.sub(r'http\\S+', '', s)\n",
    "\n",
    "def remove_tag(s):\n",
    "  return re.sub(r'<.*?>', ' ', s)\n",
    "\n",
    "def lower_words(s):\n",
    "   return s.lower()\n",
    "\n",
    "def remove_words_with_nums(s):\n",
    "  return re.sub(r\"\\S*\\d\\S*\", \"\", s)\n",
    "\n",
    "def remove_special_character(s):\n",
    "  return re.sub('[^A-Za-z0-9]+', ' ', s)\n",
    "\n",
    "def remove_stopword(s):\n",
    "    res = ' '.join([word for word in s.split(' ') if word not in stopwords.words('english')])\n",
    "    return res\n",
    "\n",
    "def lemmatization(s):\n",
    "    res = ' '.join([lemmatizer.lemmatize(word) for word in s.split(' ')])\n",
    "    return res\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = remove_url(text)\n",
    "    text = remove_tag(text)\n",
    "    text = lower_words(text)\n",
    "    text = remove_words_with_nums(text)\n",
    "    text = remove_special_character(text)\n",
    "    text = remove_stopword(text)\n",
    "    text = lemmatization(text)\n",
    "    return text\n",
    "\n",
    "trainingSet['question_body'] = trainingSet['question_body'].apply(preprocess_text)\n",
    "trainingSet['answer'] = trainingSet['answer'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702d6e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM QUESTION BODY AFTER MINING\n",
      "---------------------------------------------------------------\n",
      "site migrating wordpress need add property user edit e g address city state business name etc along property administrator edit isactive canemail displayed user addition need able display property table similar plugin member list display custom field displaying well given requirement attempted use combination cimy user extra field member list member list grid option display extra field created plugin would recommend approach edit guess crux question preferred method add property user \n",
      "\n",
      "RANDOM ANSWER AFTER MINING\n",
      "---------------------------------------------------------------\n",
      "answer first part question put class ttt user profile addon github class offer simple interface add field profile page added example checkbox subclass code initialize per function php work plugin course build placeholder add separate filter markup input value make extending class easier set custom capability showing saving field per constructor call whole work reduced simple init function add action init ttt init profile addons register extra field user profile editor function ttt init profile addons globals ttt show profile new ttt user profile checkbox array name gt ttt show profile label gt show short profile box post th gt td gt lt input type checkbox name name id id checked gt label cap show gt edit post cap save gt edit user add field adding value member table something still todo list oh probably mention another class replace extend default contact field ttt contactfields may case oop overdone \n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM QUESTION BODY AFTER MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['question_body'].values[344])\n",
    "\n",
    "print(\"\\nRANDOM ANSWER AFTER MINING\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(trainingSet['answer'].values[344])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291b3852",
   "metadata": {},
   "source": [
    "## Creating a Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3775e",
   "metadata": {},
   "source": [
    "In this project, we will generate a simple model composed of the following layers:\n",
    "<br /> 1. Input: \n",
    "<br /> 2. Embedding: We will do this in order to have space for more semantic nuances in sentences.\n",
    "<br /> 3. Bidirectional RNN:\n",
    "<br /> 4. Global Max Pooling: \n",
    "<br /> 5. Dense Layer:\n",
    "<br /> 6. Dense Layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06592752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 768)         3840000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 120)         99480     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1936      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 3,941,501\n",
      "Trainable params: 3,941,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# parameters used for typical embeddings\n",
    "maxLength = 1000\n",
    "maxFeatures = 5000 \n",
    "embeddingSize = 768\n",
    "\n",
    "inp = Input(shape=(maxLength,)) # returns a shape tuple of ints, size of the maxLength of \n",
    "\n",
    "z = Embedding(maxFeatures,embeddingSize,input_length = maxLength)(inp)\n",
    "z = Bidirectional(SimpleRNN(60,return_sequences='True'))(z)\n",
    "z = GlobalMaxPool1D()(z)\n",
    "z = Dense(16,activation='relu')(z)\n",
    "z = Dense(5,activation='softmax')(z)\n",
    "\n",
    "model = Model(inputs=inp,outputs=z)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1ba16ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADDED AND TOKENIZED SEQUENCES, ALL VECTORS HAVE THE SAME LENGTH\n",
      "----------------------------------------------------------------\n",
      "xTrain Sequence, Padded and Tokenized:  (4559, 1000)\n",
      "yTrain                               :  (4559,)\n",
      "xVal Sequence, Padded and Tokenized  :  (1520, 1000)\n",
      "yVal                                 :  (1520,)\n",
      "Epoch 1/10\n",
      "36/36 - 54s - loss: 1.3087 - accuracy: 0.4350 - val_loss: 1.0614 - val_accuracy: 0.5197\n",
      "Epoch 2/10\n",
      "36/36 - 62s - loss: 0.7407 - accuracy: 0.7951 - val_loss: 0.6744 - val_accuracy: 0.8263\n",
      "Epoch 3/10\n",
      "36/36 - 64s - loss: 0.3239 - accuracy: 0.9566 - val_loss: 0.4638 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "36/36 - 65s - loss: 0.1169 - accuracy: 0.9868 - val_loss: 0.4138 - val_accuracy: 0.8546\n",
      "Epoch 5/10\n",
      "36/36 - 64s - loss: 0.0519 - accuracy: 0.9945 - val_loss: 0.4162 - val_accuracy: 0.8605\n",
      "Epoch 6/10\n",
      "36/36 - 65s - loss: 0.0234 - accuracy: 0.9987 - val_loss: 0.4310 - val_accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "36/36 - 64s - loss: 0.0153 - accuracy: 0.9982 - val_loss: 0.4911 - val_accuracy: 0.8572\n",
      "Epoch 8/10\n",
      "36/36 - 64s - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.4783 - val_accuracy: 0.8592\n",
      "Epoch 9/10\n",
      "36/36 - 64s - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.4868 - val_accuracy: 0.8625\n",
      "Epoch 10/10\n",
      "36/36 - 66s - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.4981 - val_accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2bc1b00040>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yLabel = LabelEncoder() # label encodeer\n",
    "labels = yLabel.fit_transform(trainingSet['category']) # used for the labels of each category\n",
    "\n",
    "yTrain = labels # set x training vars as the labels (categories)\n",
    "# setup the training (x,y) and testing (X,Y) 'question_body' datasets.  test_size default 0.25, random_state for shuffling data\n",
    "xTrain,xTest,yTrain, yTest = train_test_split(trainingSet['question_body'], yTrain, test_size=0.25,random_state=30)\n",
    "\n",
    "tokenizer = Tokenizer(num_words = maxFeatures) # setup the tokenizer, num words in question_body to vectorize\n",
    "tokenizer.fit_on_texts(list(xTrain)) # \n",
    "\n",
    "xVal = xTest # set xVal to xTest\n",
    "xVal = tokenizer.texts_to_sequences(xVal) # transform xVal into sequence of integers\n",
    "\n",
    "xTrain = tokenizer.texts_to_sequences(xTrain) # transform xTrain into sequence of integers\n",
    "\n",
    "xTrain = pad_sequences(xTrain, maxlen = maxLength) # pad sequence so that the vectors can have the same lengths\n",
    "xVal   = pad_sequences(xVal, maxlen = maxLength) # pad sequence so that the vectors can have the same lengths\n",
    "\n",
    "yVal = yTest\n",
    "\n",
    "print(\"PADDED AND TOKENIZED SEQUENCES, ALL VECTORS HAVE THE SAME LENGTH\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "print(\"xTrain Sequence, Padded and Tokenized: \", xTrain.shape)\n",
    "print(\"yTrain                               : \", yTrain.shape)\n",
    "\n",
    "print(\"xVal Sequence, Padded and Tokenized  : \", xVal.shape)\n",
    "print(\"yVal                                 : \", yVal.shape)\n",
    "\n",
    "\n",
    "model.fit(xTrain, yTrain, batch_size=128, epochs=10, verbose=2,validation_data = (xVal,yVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4710b2b",
   "metadata": {},
   "source": [
    "Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de72661f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "model = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\")\n",
    "trainingSet['question_title'] = trainingSet['question_title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea87c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = [model([trainingSet.iloc[i].question_title])[0] for i in range(trainingSet.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "658e66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "def query_match(query):\n",
    "    query_embedding = model([query])\n",
    "    sim = cosine_similarity(question_embeddings, query_embedding)\n",
    "    sim_scores = [sim[i][0] for i in range(sim.shape[0])]\n",
    "    return np.argmax(sim_scores)\n",
    "    print(np.shape(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8281dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE QUESTION\n",
      "-----------------------------\n",
      "How can I understand whether my C implementation is constant-time or not (i.e. resistant to timing attacks)\n",
      "\n",
      "PREPROCESSED QUESTION\n",
      "-----------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40073/2819636043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPREPROCESSED QUESTION'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "print('SAMPLE QUESTION')\n",
    "print(\"-----------------------------\")\n",
    "question = 'How can I understand whether my C implementation is constant-time or not (i.e. resistant to timing attacks)'\n",
    "print(question)\n",
    "\n",
    "print('\\nPREPROCESSED QUESTION')\n",
    "print(\"-----------------------------\")\n",
    "question = preprocess_text(question)\n",
    "print(question)\n",
    "\n",
    "query_idx = query_match(question)\n",
    "\n",
    "print('\\nSEMANTIC SIMILARITY')\n",
    "print(\"-----------------------------\")\n",
    "print(trainingSet.iloc[query_idx].question_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf2391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7866221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d1e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0920225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
